name: AWS integration test PR

on:
  pull_request:

jobs:
  run-databricks-notebook:
    runs-on: html_publisher
    steps:
      - name: Checkout repo
        uses: actions/checkout@v2

      - name: Run a databricks notebook
        uses: databricks/run-notebook@v0
        with:
          local-notebook-path: RUNME.py
          git-commit: ${{ github.event.pull_request.head.sha }}
          databricks-host: https://e2-demo-west.cloud.databricks.com
          databricks-token: ${{ secrets.DEPLOYMENT_TARGET_TOKEN_AWS }}
          new-cluster-json: >
            {
              "num_workers": 1,
              "spark_version": "13.3.x-scala2.12",
              "node_type_id": "i3.large",
              "aws_attributes": {
                "availability": "ON_DEMAND"
              },
              "custom_tags": {
                "ResourceClass": "JobCluster"
              },
              "policy_id": "E05E27B13F0003A0"
            }
          notebook-params-json: >
            {
              "run_job": "True"
            }
          access-control-list-json: >
            [
              {
                "group_name": "users",
                "permission_level": "CAN_VIEW"
              }
            ]
